{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Analysis of the Execution-Based Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract error mitigation flow data from testresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from codetransbench.utils.dataset_information import language_pairs\n",
    "from codetransbench.utils.config import load_config\n",
    "\n",
    "from codetransbench.translation.translate_open_source import FILE_EXTENSIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"../codetransbenchmark/config/config.yaml\"\n",
    "if path_to_config:\n",
    "    config = load_config(path_to_config)\n",
    "else:\n",
    "    config = load_config()\n",
    "output_dir = config.output_dir\n",
    "dataset_dir = config.dataset_dir\n",
    "testresults_dir = config.testresults_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set output post-processing\n",
    "Set to None to use the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opp = None#\"controlled\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import build_combined_reporting as build_combined_reporting\n",
    "build_combined_reporting.main_general(config, opp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with loaded data for analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "if opp:\n",
    "    combined_raw_count = pd.read_csv(Path(\"./data\") / f\"combined_exec_{opp}.csv\")\n",
    "    raw_combined = pd.read_csv(Path(\"./data\") / f\"raw_combined_mitigation_{opp}.csv\", index_col=0)\n",
    "    raw_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opp == None:\n",
    "    combined_raw_count = pd.read_csv(Path(\"./data\") / \"combined_exec.csv\")\n",
    "    raw_combined = pd.read_csv(Path(\"./data\") / \"raw_combined_mitigation.csv\", index_col=0)\n",
    "    raw_combined\n",
    "    combined_raw_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup of identifyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prettify identifiers\n",
    "raw_combined[\"model_name\"] = raw_combined[\"model_name\"].str.split(r'_').str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cat = [\"success\", \"compile\", \"runtime\", \"incorrect\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering of the tasks with faulty source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_without_faluty_source = raw_combined.query(\"result_1 != 'faulty source' and result_1 != 'unicode error'\")\n",
    "combined = combined_without_faluty_source[['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'target_filename']].groupby(['dataset', 'model_name', 'template', 'source_lang', 'target_lang', 'result_1']).count()\n",
    "combined_without_faluty_source.loc[:,\"result_1\"] = pd.Categorical(combined_without_faluty_source.loc[:,\"result_1\"], categories = result_cat, ordered=True)\n",
    "if opp == None:\n",
    "    combined_without_faluty_source.loc[:,\"result_2\"] = pd.Categorical(combined_without_faluty_source.loc[:,\"result_2\"], categories = result_cat, ordered=True)\n",
    "    combined_without_faluty_source.loc[:,\"result_3\"] = pd.Categorical(combined_without_faluty_source.loc[:,\"result_3\"], categories = result_cat, ordered=True)\n",
    "combined_without_faluty_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Matplotlib plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"matplotlib\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"thesis_style_sheet.mplstyle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlap in outcome in the 1st iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_without_faluty_source.filter(['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'source_filename', 'target_filename']).groupby([\"source_filename\", \"target_filename\", \"result_1\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_without_faluty_source.loc[combined_without_faluty_source.model_name.str.contains(\"mistral\")].filter(['model_name', 'template', 'result_1', 'source_filename', 'target_filename']).groupby([\"source_filename\", \"target_filename\", \"result_1\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_without_faluty_source.loc[combined_without_faluty_source.model_name == \"mistral\"].filter(['model_name', 'template', 'result_1', 'source_filename', 'target_filename']).groupby([\"source_filename\", \"target_filename\", \"result_1\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_without_faluty_source.loc[combined_without_faluty_source.template == \"controlled_md\"].filter(['model_name', 'template', 'result_1', 'source_filename', 'target_filename']).groupby([\"source_filename\", \"target_filename\", \"result_1\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of successful translation pairs vs the number of models that were successful. Template: controlled_md\n",
    "If a file was translated successfully, how many models were successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT USE THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# success_dist_files = combined_without_faluty_source.query(\"template == 'controlled_md' and result_1 == 'success'\").filter(['model_name', 'template', 'result_1', 'source_filename', 'target_filename']).groupby([\"source_filename\", \"target_filename\", \"result_1\"]).count().rename(columns={\"model_name\": \"successful models\"}).groupby(\"successful models\").count().rename(columns={\"template\":\"Ratio of tasks\"})\n",
    "# success_dist_files.div(success_dist_files.sum()).plot(kind=\"bar\", rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results without iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reset = combined.reset_index()\n",
    "combined_reset.loc[:,\"result_1\"] = pd.Categorical(combined_reset.loc[:,\"result_1\"], categories = result_cat, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_pivot = pd.pivot_table(combined_reset, values=\"target_filename\", index=['dataset', 'model_name', 'template', 'source_lang', 'target_lang'], columns=[\"result_1\"], aggfunc=sum,\n",
    "               fill_value=0,\n",
    "               margins=True)\n",
    "#combined_pivot = combined_pivot.div(combined_pivot.iloc[:,-1], axis=0 )\n",
    "# combined_pivot.to_csv(Path(\"./data\") / \"combined_exec_pivot.csv\")\n",
    "# combined_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables for the thesis to give the complete overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pivot_alternative = pd.pivot_table(combined_reset, values=\"target_filename\", index=['dataset', \"result_1\"], columns=['model_name', 'template'], aggfunc=[\"sum\"],\n",
    "               fill_value=0,\n",
    "               margins=True)\n",
    "combined_pivot_alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table per language pair\n",
    "\n",
    "Correct calculation of Percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "combined_pivot = combined_pivot[['success', 'compile', 'runtime','incorrect', 'All']]\n",
    "\n",
    "\n",
    "combined_pivot_without_index = combined_pivot.reset_index()\n",
    "combined_pivot_without_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each language pair:\n",
    "languages = [\"Python\", \"Java\", \"Go\", \"Rust\", \"C#\"]\n",
    "\n",
    "pl_permutations = itertools.permutations(languages, 2)\n",
    "valid_permutations = set()\n",
    "for pair in pl_permutations:\n",
    "    if pair[0] in [\"Python\", \"Java\", \"Go\"]:  # \"C\", \"C++\":\n",
    "        valid_permutations.add(pair)\n",
    "for pair in valid_permutations:\n",
    "    filtered = combined_pivot_without_index[(combined_pivot_without_index[\"source_lang\"] == pair[0]) & (combined_pivot_without_index[\"target_lang\"] == pair[1]) & (combined_pivot_without_index[\"template\"] != \"LIT\")]\n",
    "    for col_to_remove in [\"source_lang\", \"target_lang\"]:\n",
    "        filtered = filtered.loc[:, filtered.columns != col_to_remove]\n",
    "    iteration_1_stats = filtered.rename(columns={\"model_name\": \"Model\", \"dataset\": \"Dataset\", \"template\": \"Prompt\"}).groupby(['Dataset', 'Model', 'Prompt']).sum()\n",
    "    s = iteration_1_stats.groupby([\"Model\", \"Prompt\"]).sum()\n",
    "    index_frame = s.index.to_frame().reset_index(drop=True)\n",
    "    index_frame[\"Dataset\"] = \"All\"\n",
    "    index_frame = index_frame.filter(['Dataset', 'Model', 'Prompt'])\n",
    "    s.index = pd.MultiIndex.from_frame(index_frame)\n",
    "    iteration_1_stats =pd.concat([iteration_1_stats, s]).sort_index().iloc[:, :]\n",
    "    iteration_1_stats_percent = iteration_1_stats.div(iteration_1_stats.iloc[:,-1], axis=0) * 100\n",
    "    iteration_1_stats_percent = iteration_1_stats_percent.stack().unstack([\"Model\", \"Prompt\"]).dropna(axis=\"columns\")\n",
    "    iteration_1_stats_percent.rename(inplace=True, columns={\"codestral\": \"Codestral\", \"dolphin-2.6-mistral\": \"D-Mistral\", \"dolphin-2.6-phi-2\": \"D-Phi-2\", \"dolphin-2.7-mixtral\": \"D-Mixtral\", \"llama3-8b\": \"Llama 3\", \"phi3\": \"Phi-3\", \"mistral\": \"Mistral\", \"controlled_md\": \"MD\", \"via_description\": \"VT\", \"mixtral\": \"Mixtral\", \"controlled\": \"RM\"}, index={\"infinite loop\": \"loop\"})\n",
    "    iteration_1_stats.to_csv(f\"./tables/iteration_1_stats{pair[0]}_{pair[1]}.csv\")\n",
    "    iteration_1_stats_percent.to_csv(f\"./tables/iteration_1_stats_percent_{pair[0]}_{pair[1]}.csv\")\n",
    "    iteration_1_stats_percent.to_latex(f\"./tables_tex/iteration_1_stats_percent_{pair[0]}_{pair[1]}.tex\", float_format=\"%.2f\")\n",
    "print(pair)\n",
    "iteration_1_stats_percent # show example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All languages aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_1_stats = combined_pivot.query(\"source_lang != 'Go'\").groupby(['dataset', 'model_name', 'template']).sum()\n",
    "s = iteration_1_stats.groupby([\"model_name\", \"template\"]).sum()\n",
    "index_frame = s.index.to_frame().reset_index(drop=True)\n",
    "index_frame[\"dataset\"] = \"All\"\n",
    "index_frame = index_frame.filter(['dataset', 'model_name', 'template'])\n",
    "s.index = pd.MultiIndex.from_frame(index_frame)\n",
    "iteration_1_stats =pd.concat([iteration_1_stats, s]).sort_index().iloc[1:, :]\n",
    "iteration_1_stats.to_csv(f\"./tables/iteration_1_stats_total.csv\")\n",
    "iteration_1_stats.index.rename({\"model_name\": \"Model\", \"dataset\": \"Dataset\", \"template\": \"Prompt\"}, inplace=True)\n",
    "# iteration_1_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_1_stats_percent = iteration_1_stats.div(iteration_1_stats.iloc[:,-1], axis=0) * 100\n",
    "iteration_1_stats_percent = iteration_1_stats_percent\n",
    "#iteration_1_stats_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_1_stats_percent = iteration_1_stats_percent.stack().unstack([\"Model\", \"Prompt\"])\n",
    "if opp == None:\n",
    "    iteration_1_stats_percent = iteration_1_stats_percent.drop(columns=[\"LIT\"], level=1)\n",
    "iteration_1_stats_percent = iteration_1_stats_percent.dropna(axis=\"columns\").round(2)\n",
    "#iteration_1_stats_percent = iteration_1_stats_percent.stack().unstack([\"Model\", \"Prompt\"]).dropna(axis=\"columns\").round(2)\n",
    "iteration_1_stats_percent.rename(inplace=True, columns={\"codestral\": \"Codestral\", \"dolphin-2.6-mistral\": \"D-Mistral\", \"dolphin-2.6-phi-2\": \"D-Phi-2\", \"dolphin-2.7-mixtral\": \"D-Mixtral\", \"llama3-8b\": \"Llama 3\", \"phi3\": \"Phi-3\", \"mistral\": \"Mistral\", \"controlled_md\": \"MD\", \"via_description\": \"VT\", \"mixtral\": \"Mixtral\", \"controlled\": \"RM\"}, index={\"infinite loop\": \"loop\"})\n",
    "if opp == None:\n",
    "    iteration_1_stats_percent.to_csv(f\"./tables/iteration_1_stats_percent_total.csv\", float_format=\"%.2f\")\n",
    "    iteration_1_stats_percent.to_latex(f\"./tables_tex/iteration_1_stats_percent_total.tex\", float_format=\"%.2f\")\n",
    "else:\n",
    "    iteration_1_stats_percent.to_csv(f\"./tables/iteration_1_stats_percent_{opp}.csv\", float_format=\"%.2f\")\n",
    "    iteration_1_stats_percent.to_latex(f\"./tables_tex/iteration_1_stats_percent_{opp}.tex\", float_format=\"%.2f\")\n",
    "iteration_1_stats_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language analysis via table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = combined_pivot_without_index[combined_pivot_without_index[\"template\"] == \"controlled_md\"]\n",
    "for col_to_remove in [\"template\", 'dataset', 'model_name']:\n",
    "    filtered = filtered.loc[:, filtered.columns != col_to_remove]\n",
    "iteration_1_stats_controlled_md = filtered.groupby(['source_lang', 'target_lang']).sum()\n",
    "iteration_1_stats_controlled_md_ratio = iteration_1_stats_controlled_md.div(iteration_1_stats_controlled_md.iloc[:,-1], axis=0) * 100\n",
    "\n",
    "iteration_1_stats_controlled_md_ratio.iloc[:,:-1]#.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import PercentFormatter\n",
    "import numpy as np\n",
    "def make_bar_plot_combined_pivot(filter_query: str, grouping: list, title: str | None = None, subgroup: str| None = None, percentage=True, only_success=True, xlabel=None, ylabel=None, bar_labels=False, xrot=0, label_col=5):\n",
    "    all_index_col = [\"dataset\", \"model_name\", \"template\", \"source_lang\", \"target_lang\"]\n",
    "    \n",
    "    combined_pivot_without_index = combined_pivot.reset_index()\n",
    "    filtered = combined_pivot_without_index.query(filter_query)\n",
    "    for col_to_remove in [x for x in all_index_col if x not in grouping]:\n",
    "        filtered = filtered.loc[:, filtered.columns != col_to_remove]\n",
    "    graph_data = filtered.groupby(grouping).sum()\n",
    "    if percentage:\n",
    "        graph_data = graph_data.div(graph_data.iloc[:,-1], axis=0) * 100\n",
    "\n",
    "    if subgroup and subgroup in grouping:\n",
    "        index_level_subgroup = grouping.index(subgroup)\n",
    "        graph_data=graph_data.unstack(index_level_subgroup)\n",
    "\n",
    "\n",
    "    if only_success:\n",
    "        graph_data=graph_data.loc[:, \"success\"]\n",
    "    else:\n",
    "        graph_data = graph_data.iloc[:,:-1]\n",
    "\n",
    "    graph_data.rename(inplace=True, columns={\"codestral\": \"Codestral\", \"dolphin-2.6-mistral\": \"D-Mistral\", \"dolphin-2.6-phi-2\": \"D-Phi-2\", \"dolphin-2.7-mixtral\": \"D-Mixtral\", \"llama3-8b\": \"Llama 3\", \"phi3\": \"Phi-3\", \"mistral\": \"Mistral\", \"controlled_md\": \"MD\", \"via_description\": \"VT\", \"mixtral\": \"Mixtral\", \"controlled\": \"RM\"}, index={\"infinite loop\": \"loop\"})\n",
    "    graph_data.rename(inplace=True, index={\"codestral\": \"Codestral\", \"dolphin-2.6-mistral\": \"D-Mistral\", \"dolphin-2.6-phi-2\": \"D-Phi-2\", \"dolphin-2.7-mixtral\": \"D-Mixtral\", \"llama3-8b\": \"Llama 3\", \"phi3\": \"Phi-3\", \"mistral\": \"Mistral\", \"controlled_md\": \"MD\", \"via_description\": \"VT\", \"mixtral\": \"Mixtral\", \"controlled\": \"RM\"}, columns={\"infinite loop\": \"loop\"})\n",
    "    graph_data.rename(inplace=True, columns={\"avatar\": \"AVATAR\", \"codenet\": \"CodeNet\", \"bithacks\": \"BitHacks\"})\n",
    "    graph_data.rename(inplace=True, index={\"avatar\": \"AVATAR\", \"codenet\": \"CodeNet\", \"bithacks\": \"BitHacks\"})\n",
    "    print(graph_data)\n",
    "    \n",
    "\n",
    "    ax = graph_data.plot(kind='bar', title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    ax.legend(bbox_to_anchor=(0, 1.02, 1, 0.2), loc=\"lower left\",\n",
    "                mode=\"expand\", borderaxespad=0, ncol=label_col)\n",
    "    ax.tick_params(axis='x', labelrotation=xrot)\n",
    "    if percentage:\n",
    "        ax.set_ylim([0, 100])\n",
    "        ax.yaxis.set_major_formatter(PercentFormatter())\n",
    "    if bar_labels:\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fmt='%.2f')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md'\",\n",
    "    ['dataset', 'model_name'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Dataset\",\n",
    "    ylabel=\"Percentage of Successful Samples\",\n",
    "    xrot=90,\n",
    "    subgroup=\"model_name\"\n",
    ")\n",
    "\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md'\",\n",
    "    ['dataset', 'model_name'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Model\",\n",
    "    ylabel=\"Percentage of Successful Samples\",\n",
    "    xrot=90,\n",
    "    subgroup=\"dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance in the outcomes by model for the controlled_md template\n",
    "# Classification of the outputs of the initial translation round \\nwith the controlled_md template\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md'\",\n",
    "    ['model_name'],\n",
    "    percentage=True,\n",
    "    only_success=False,\n",
    "    xlabel=\"Model\",\n",
    "    ylabel=\"Outcome Rate\",\n",
    "    xrot=-45\n",
    ")\n",
    "#### TODO links nach rechts unten ticks anschrägen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance in the outcomes by template for mistral-7b\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"model_name == 'mistral'\",\n",
    "    ['template'],\n",
    "    percentage=True,\n",
    "    only_success=False,\n",
    "    xlabel=\"Prompt Template\",\n",
    "    ylabel=\"Percentage of Samples\"\n",
    ")\n",
    "# Variance in the outcomes by template for dolphin-2.6-mistral-7b\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"model_name == 'dolphin-2.6-mistral'\",\n",
    "    ['template'],\n",
    "    percentage=True,\n",
    "    only_success=False,\n",
    "    xlabel=\"Prompt Template\",\n",
    "    ylabel=\"Percentage of Samples\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create subplots by Source PL\n",
    "# make_bar_plot_combined_pivot(\n",
    "#     \"template == 'controlled_md'\",\n",
    "#     ['source_lang', 'target_lang'],\n",
    "#     percentage=True,\n",
    "#     only_success=False,\n",
    "#     xlabel=\"Language Pair\",\n",
    "#     ylabel=\"Percentage of Samples\",\n",
    "#     xrot=-45\n",
    "# )\n",
    "\n",
    "\n",
    "# subplots by Source PL\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=-45,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n",
    "print(\"llama 3\")\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md' and model_name == 'llama3-8b'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=-45,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n",
    "print(\"D-Phi-2\")\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md' and model_name == 'dolphin-2.6-phi-2'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=-45,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled' and model_name == 'dolphin-2.6-phi-2'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=-45,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n",
    "print(\"phi3\")\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md' and model_name == 'phi3'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=-45,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n",
    "print(\"codestral\")\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md' and model_name == 'codestral'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=0,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n",
    "plt.savefig(\"./plots/codestral_lanugage_pairs.pdf\")\n",
    "print(\"D-Mixtral\")\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md' and model_name == 'dolphin-2.7-mixtral'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=-45,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n",
    "print(\"Mixtral\")\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md' and model_name == 'mixtral'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=-45,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n",
    "print(\"D-Mistral\")\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md' and model_name == 'dolphin-2.6-mistral'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=-45,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n",
    "print(\"Mistral\")\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"template == 'controlled_md' and model_name == 'mistral'\",\n",
    "    ['source_lang', 'target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=-45,\n",
    "    subgroup=\"target_lang\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Variance in the outcomes by source PL for Codestral\n",
    "# make_bar_plot_combined_pivot(\n",
    "#     \"model_name == 'codestral'\",\n",
    "#     ['source_lang', 'target_lang'],\n",
    "#     percentage=True,\n",
    "#     only_success=False,\n",
    "#     xlabel=\"Language Pair\",\n",
    "#     ylabel=\"Outcome Rate\",\n",
    "#     xrot=-90\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance in the outcomes by source PL for Codestral\n",
    "make_bar_plot_combined_pivot(\n",
    "   \"template == 'controlled_md'\",# \"model_name.str.contains('mixtral', na=False) or model_name.str.contains('mistral', na=False)\",\n",
    "    ['target_lang', 'model_name'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Target Language\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=45,\n",
    "    subgroup=\"model_name\"\n",
    ")\n",
    "\n",
    "# Variance in the outcomes by source PL for Codestral\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"model_name.str.contains('mixtral', na=False)\",\n",
    "    ['target_lang', 'model_name'],\n",
    "    percentage=True,\n",
    "    only_success=True,\n",
    "    xlabel=\"Target Language\",\n",
    "    ylabel=\"Success Rate\",\n",
    "    xrot=45,\n",
    "    subgroup=\"model_name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance in the outcomes for Codestral\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"model_name == 'codestral'\",\n",
    "    ['template'],\n",
    "    percentage=True,\n",
    "    only_success=False,\n",
    "    xlabel=\"Outcomes for translations\",\n",
    "    ylabel=\"Outcome Rate\",\n",
    "    bar_labels=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance in the outcomes by source PL for Codestral\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"model_name == 'codestral'\",\n",
    "    ['source_lang'],\n",
    "    percentage=True,\n",
    "    only_success=False,\n",
    "    xlabel=\"Source PL\",\n",
    "    ylabel=\"Outcome Rate\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the next diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Variance in the Outcomes by Target PL for Codestral\"\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"model_name == 'codestral'\",\n",
    "    ['target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=False,\n",
    "    xlabel=\"Target PL\",\n",
    "    ylabel=\"Outcome Rate\",\n",
    "    xrot=-45\n",
    ")\n",
    "\n",
    "make_bar_plot_combined_pivot(\n",
    "    \"model_name == 'dolphin-2.7-mixtral'\",\n",
    "    ['target_lang'],\n",
    "    percentage=True,\n",
    "    only_success=False,\n",
    "    xlabel=\"Target PL\",\n",
    "    ylabel=\"Outcome Rate\",\n",
    "    xrot=-45\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results iterative approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_without_faluty_source = raw_combined.query(\"result_1 != 'faulty source' and result_1 != 'unicode error'\")#.query(\"target_lang == 'Go'\")\n",
    "combined_iterative = combined_without_faluty_source[['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'result_3', 'target_filename']]#.groupby(['dataset', 'model_name', 'template', 'source_lang', 'target_lang', 'result_1']).count()\n",
    "combined_iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_template_iteration_2 = list(combined_iterative[['model_name', 'template', 'result_2', 'target_filename']].groupby(['model_name', 'template', 'result_2']).count().reset_index()[[\"model_name\", \"template\"]].value_counts().index)\n",
    "model_template_iteration_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = combined_without_faluty_source[['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'target_filename']]\n",
    "# Group the DataFrame by 'model_name' and 'template', then count the number of non-NaN results for each group\n",
    "grouped_df = current_df.groupby(['model_name', 'template']).result_2.count().reset_index()\n",
    "grouped_df.columns = ['model_name', 'template', 'count_non_nan_result_2']\n",
    "# Filter the original DataFrame to only include rows where the count of non-NaN results is greater than 0 (there was a 2nd iteration)\n",
    "df_filtered = current_df.merge(grouped_df, on=['model_name', 'template']).drop_duplicates(subset=['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'target_filename'])\n",
    "df_filtered = df_filtered[df_filtered['count_non_nan_result_2'] > 0]\n",
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.drop_duplicates([\"model_name\", \"template\"])[[\"model_name\", \"template\", \"count_non_nan_result_2\"]].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_total_second_iteration = df_filtered[['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'target_filename']].fillna({\"result_2\": \"success\"})\n",
    "results_total_second_iteration.groupby(['dataset', 'model_name', 'template', 'source_lang', 'target_lang'])\n",
    "\n",
    "grouped = results_total_second_iteration.groupby(['dataset', 'model_name', 'template', 'source_lang', 'target_lang'])\n",
    "result_1_count = grouped['result_1'].apply(lambda x: pd.Series(x).value_counts())\n",
    "result_2_count = grouped['result_2'].apply(lambda x: pd.Series(x).value_counts())\n",
    "combined_count = pd.merge(result_1_count.to_frame(), result_2_count.to_frame(), how=\"outer\", left_index=True, right_index=True).fillna(0).convert_dtypes(\"int\")\n",
    "combined_count[\"change 1->2\"] = combined_count[\"result_2\"] - combined_count['result_1']\n",
    "combined_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All language pairs combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_fix = \"controlled_md\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = results_total_second_iteration.groupby(['dataset', 'model_name', 'template'])\n",
    "result_1_count = grouped['result_1'].apply(lambda x: pd.Series(x).value_counts())\n",
    "result_2_count = grouped['result_2'].apply(lambda x: pd.Series(x).value_counts())\n",
    "combined_count = pd.merge(result_1_count.to_frame(), result_2_count.to_frame(), how=\"outer\", left_index=True, right_index=True).fillna(0).convert_dtypes(\"int\")\n",
    "combined_count[\"change 1->2\"] = combined_count[\"result_2\"] - combined_count['result_1']\n",
    "s = combined_count.groupby(['dataset', 'model_name', 'template']).sum()\n",
    "s[\"change 1->2\"] = s[\"result_1\"]\n",
    "#s = iteration_1_stats.groupby([\"model_name\", \"template\"]).sum()\n",
    "index_frame = s.index.to_frame().reset_index(drop=True)\n",
    "index_frame[\"Category\"] = \"Total\"\n",
    "index_frame = index_frame.filter(['dataset', 'model_name', 'template', 'Category'])\n",
    "print(index_frame)\n",
    "s.index = pd.MultiIndex.from_frame(index_frame)\n",
    "combined_count =pd.concat([combined_count, s]).sort_index().iloc[:, :]\n",
    "\n",
    "combined_count\n",
    "\n",
    "all_ds = combined_count.unstack(-1).groupby([\"model_name\", \"template\"]).sum()\n",
    "index_frame = all_ds.index.to_frame().reset_index(drop=True)\n",
    "index_frame[\"dataset\"] = \"All\"\n",
    "index_frame = index_frame.filter(['dataset', 'model_name', 'template'])\n",
    "all_ds.index = pd.MultiIndex.from_frame(index_frame)\n",
    "combined_count_all =pd.concat([combined_count.unstack(-1), all_ds]).sort_index().iloc[:, :]\n",
    "combined_count_all = combined_count_all.stack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = results_total_second_iteration.groupby(['dataset', 'model_name', 'template'])\n",
    "result_1_count = grouped['result_1'].apply(lambda x: pd.Series(x).value_counts())\n",
    "result_2_count = grouped['result_2'].apply(lambda x: pd.Series(x).value_counts())\n",
    "combined_count = pd.merge(result_1_count.to_frame(), result_2_count.to_frame(), how=\"outer\", left_index=True, right_index=True).fillna(0).convert_dtypes(\"int\")\n",
    "combined_count[\"change 1->2\"] = combined_count[\"result_2\"] - combined_count['result_1']\n",
    "s = combined_count.groupby(['dataset', 'model_name', 'template']).sum()\n",
    "s[\"change 1->2\"] = s[\"result_1\"]\n",
    "#s = iteration_1_stats.groupby([\"model_name\", \"template\"]).sum()\n",
    "index_frame = s.index.to_frame().reset_index(drop=True)\n",
    "index_frame[\"Category\"] = \"Total\"\n",
    "index_frame = index_frame.filter(['dataset', 'model_name', 'template', 'Category'])\n",
    "print(index_frame)\n",
    "s.index = pd.MultiIndex.from_frame(index_frame)\n",
    "combined_count =pd.concat([combined_count, s]).sort_index().iloc[:, :]\n",
    "\n",
    "combined_count\n",
    "\n",
    "all_ds = combined_count.unstack(-1).groupby([\"model_name\", \"template\"]).sum()\n",
    "index_frame = all_ds.index.to_frame().reset_index(drop=True)\n",
    "index_frame[\"dataset\"] = \"All\"\n",
    "index_frame = index_frame.filter(['dataset', 'model_name', 'template'])\n",
    "all_ds.index = pd.MultiIndex.from_frame(index_frame)\n",
    "combined_count_all =pd.concat([combined_count.unstack(-1), all_ds]).sort_index().iloc[:, :]\n",
    "combined_count_all = combined_count_all.stack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if template_fix == \"controlled_md\":\n",
    "    grouped = results_total_second_iteration.query(\"template == 'controlled_md'\").drop(columns=\"template\").groupby(['dataset', 'model_name'])\n",
    "    result_1_count = grouped['result_1'].apply(lambda x: pd.Series(x).value_counts())\n",
    "    result_2_count = grouped['result_2'].apply(lambda x: pd.Series(x).value_counts())\n",
    "    combined_count = pd.merge(result_1_count.to_frame(), result_2_count.to_frame(), how=\"outer\", left_index=True, right_index=True).fillna(0).convert_dtypes(\"int\")\n",
    "    combined_count[\"Diff.\"] = combined_count[\"result_2\"] - combined_count['result_1']\n",
    "    s = combined_count.groupby(['dataset', 'model_name']).sum()\n",
    "    s[\"Diff.\"] = s[\"result_1\"]\n",
    "    #s = iteration_1_stats.groupby([\"model_name\", \"template\"]).sum()\n",
    "    index_frame = s.index.to_frame().reset_index(drop=True)\n",
    "    index_frame[\"Category\"] = \"Total\"\n",
    "    index_frame = index_frame.filter(['dataset', 'model_name', 'Category'])\n",
    "    print(index_frame)\n",
    "    s.index = pd.MultiIndex.from_frame(index_frame)\n",
    "    combined_count = pd.concat([combined_count, s]).sort_index().iloc[:, :]\n",
    "\n",
    "    combined_count.drop(columns=[\"result_1\"], inplace=True)\n",
    "    combined_count.rename(columns={\"result_2\": \"Repaired\"}, inplace=True)\n",
    "\n",
    "    all_ds = combined_count.unstack(-1).groupby([\"model_name\"]).sum()\n",
    "    index_frame = all_ds.index.to_frame().reset_index(drop=True)\n",
    "    index_frame[\"dataset\"] = \"All\"\n",
    "    index_frame = index_frame.filter(['dataset', 'model_name'])\n",
    "    all_ds.index = pd.MultiIndex.from_frame(index_frame)\n",
    "    combined_count_all =pd.concat([combined_count.unstack(-1), all_ds]).sort_index().iloc[:, :]\n",
    "    combined_count_all = combined_count_all.stack()\n",
    "\n",
    "    tmp = combined_count_all.unstack(-1).stack(0)\n",
    "    tmp = tmp.div(tmp[\"Total\"], axis=0) * 100\n",
    "    combined_count_percent = tmp.unstack(-1).stack(0)\n",
    "    combined_count_percent = combined_count_percent.stack().unstack([\"model_name\"]).fillna(0).unstack(-1)\n",
    "    combined_count_percent.rename(inplace=True, columns={\"codestral\": \"Codestral\", \"dolphin-2.6-mistral\": \"D-Mistral\", \"dolphin-2.6-phi-2\": \"D-Phi-2\", \"dolphin-2.7-mixtral\": \"D-Mixtral\", \"llama3-8b\": \"Llama 3\", \"phi3\": \"Phi-3\", \"mistral\": \"Mistral\", \"controlled_md\": \"MD\", \"via_description\": \"VT\", \"mixtral\": \"Mixtral\", \"controlled\": \"RM\"}, index={\"infinite loop\": \"loop\"})\n",
    "\n",
    "    combined_count_percent.to_csv(\"./tables/iteration_2_percent.csv\")\n",
    "    combined_count_percent.to_excel(\"./tables/iteration_2_percent.xlsx\", float_format=\"%.2f\")\n",
    "    combined_count_percent.to_latex(\"./tables_tex/iteration_2_percent.tex\", float_format=\"%.2f\")\n",
    "combined_count_percent\n",
    "\n",
    "#combined_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_count_numbers = combined_count_all.stack().unstack([\"model_name\", \"template\"]).fillna(0).unstack(-1)\n",
    "combined_count_numbers.rename(inplace=True, columns={\"codestral\": \"Codestral\", \"dolphin-2.6-mistral\": \"D-Mistral\", \"dolphin-2.6-phi-2\": \"D-Phi-2\", \"dolphin-2.7-mixtral\": \"D-Mixtral\", \"llama3-8b\": \"Llama 3\", \"phi3\": \"Phi-3\", \"mistral\": \"Mistral\", \"controlled_md\": \"MD\", \"via_description\": \"VT\", \"mixtral\": \"Mixtral\", \"controlled\": \"RM\"}, index={\"infinite loop\": \"loop\"})\n",
    "combined_count_numbers.to_csv(\"./tables/iteration_2_numbers.csv\", float_format=\"\")\n",
    "combined_count_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = combined_count_all.unstack(-1).stack(0)\n",
    "tmp = tmp.div(tmp[\"Total\"], axis=0) * 100\n",
    "combined_count_percent = tmp.unstack(-1).stack(0)\n",
    "combined_count_percent = combined_count_percent.stack().unstack([\"model_name\", \"template\"]).fillna(0).unstack(-1)\n",
    "combined_count_percent.rename(inplace=True, columns={\"codestral\": \"Codestral\", \"dolphin-2.6-mistral\": \"D-Mistral\", \"dolphin-2.6-phi-2\": \"D-Phi-2\", \"dolphin-2.7-mixtral\": \"D-Mixtral\", \"llama3-8b\": \"Llama 3\", \"phi3\": \"Phi-3\", \"mistral\": \"Mistral\", \"controlled_md\": \"MD\", \"via_description\": \"VT\", \"mixtral\": \"Mixtral\", \"controlled\": \"RM\"}, index={\"infinite loop\": \"loop\"})\n",
    "\n",
    "combined_count_percent.to_csv(\"./tables/iteration_2_percent.csv\")\n",
    "combined_count_percent.to_excel(\"./tables/iteration_2_percent.xlsx\", float_format=\"%.2f\")\n",
    "combined_count_percent.to_latex(\"./tables_tex/iteration_2_percent.tex\", float_format=\"%.2f\")\n",
    "combined_count_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = combined_without_faluty_source[['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'result_3', 'target_filename']]\n",
    "# Group the DataFrame by 'model_name' and 'template', then count the number of non-NaN results for each group\n",
    "grouped_df = current_df.groupby(['model_name', 'template']).result_3.count().reset_index()\n",
    "grouped_df.columns = ['model_name', 'template', 'count_non_nan_result_3']\n",
    "# Filter the original DataFrame to only include rows where the count of non-NaN results is greater than 0 (there was a 3nd iteration)\n",
    "df_filtered = current_df.merge(grouped_df, on=['model_name', 'template']).drop_duplicates(subset=['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'result_3', 'target_filename'])\n",
    "df_filtered = df_filtered[df_filtered['count_non_nan_result_3'] > 0]\n",
    "df_filtered\n",
    "results_total_third_iteration = df_filtered[['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'result_3', 'target_filename']].fillna({\"result_2\": \"success\", \"result_3\": \"success\"})\n",
    "results_total_third_iteration.groupby(['dataset', 'model_name', 'template', 'source_lang', 'target_lang'])\n",
    "\n",
    "grouped = results_total_third_iteration.groupby(['dataset', 'model_name', 'template']) #, 'source_lang', 'target_lang'])\n",
    "result_1_count = grouped['result_1'].apply(lambda x: pd.Series(x).value_counts())\n",
    "result_2_count = grouped['result_2'].apply(lambda x: pd.Series(x).value_counts())\n",
    "result_3_count = grouped['result_3'].apply(lambda x: pd.Series(x).value_counts())\n",
    "combined_count = pd.merge(result_1_count.to_frame(), result_2_count.to_frame(), how=\"outer\", left_index=True, right_index=True).fillna(0).convert_dtypes(\"int\")\n",
    "combined_count = pd.merge(combined_count, result_3_count.to_frame(), how=\"outer\", left_index=True, right_index=True).fillna(0).convert_dtypes(\"int\")\n",
    "combined_count[\"change 1->2\"] = combined_count[\"result_2\"] - combined_count['result_1']\n",
    "combined_count[\"change 2->3\"] = combined_count[\"result_3\"] - combined_count['result_2']\n",
    "combined_count[\"change 1->3\"] = combined_count[\"result_3\"] - combined_count['result_1']\n",
    "combined_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = combined_count.groupby(['dataset', 'model_name', 'template']).sum()\n",
    "s[\"change 1->2\"] = s[\"result_1\"]\n",
    "s[\"change 2->3\"] = s[\"result_1\"]\n",
    "s[\"change 1->3\"] = s[\"result_1\"]\n",
    "\n",
    "index_frame = s.index.to_frame().reset_index(drop=True)\n",
    "index_frame[\"Category\"] = \"Total\"\n",
    "index_frame = index_frame.filter(['dataset', 'model_name', 'template', 'Category'])\n",
    "print(index_frame)\n",
    "s.index = pd.MultiIndex.from_frame(index_frame)\n",
    "combined_count_with_total =pd.concat([combined_count, s]).sort_index()\n",
    "combined_count_with_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped = results_total_third_iteration.groupby(['dataset', 'model_name', 'template', 'source_lang', 'target_lang'])\n",
    "result_1_count = grouped['result_1'].apply(lambda x: pd.Series(x).value_counts())\n",
    "result_2_count = grouped['result_2'].apply(lambda x: pd.Series(x).value_counts())\n",
    "result_3_count = grouped['result_3'].apply(lambda x: pd.Series(x).value_counts())\n",
    "combined_count = pd.merge(result_1_count.to_frame(), result_2_count.to_frame(), how=\"outer\", left_index=True, right_index=True).fillna(0).convert_dtypes(\"int\")\n",
    "combined_count[\"change 1->2\"] = combined_count[\"result_2\"] - combined_count['result_1']\n",
    "combined_count[\"change 2->3\"] = combined_count[\"result_3\"] - combined_count['result_2']\n",
    "combined_count[\"change 1->3\"] = combined_count[\"result_3\"] - combined_count['result_1']\n",
    "combined_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = combined_count_with_total.unstack(-1).stack(0)\n",
    "tmp = tmp.div(tmp[\"Total\"], axis=0) * 100\n",
    "combined_count_percent = tmp.unstack(-1).stack(0)\n",
    "combined_count_percent = combined_count_percent.stack().unstack([\"model_name\", \"template\"]).fillna(0).unstack(-1)\n",
    "combined_count_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_count_with_total.unstack().groupby([\"model_name\", \"template\"]).sum().stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = combined_count_with_total.unstack().groupby([\"model_name\", \"template\"]).sum().stack().unstack(-1).stack(0)\n",
    "tmp = tmp.div(tmp[\"Total\"], axis=0) * 100\n",
    "combined_count_percent = tmp.unstack(-1).stack(0)\n",
    "combined_count_percent = combined_count_percent.stack().unstack([\"model_name\", \"template\"]).fillna(0).unstack(-1)\n",
    "combined_count_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Sankey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df = combined_without_faluty_source[['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'result_3', 'target_filename']]\n",
    "# Group the DataFrame by 'model_name' and 'template', then count the number of non-NaN results for each group\n",
    "grouped_df = current_df.groupby(['model_name', 'template']).result_3.count().reset_index()\n",
    "grouped_df.columns = ['model_name', 'template', 'count_non_nan_result_3']\n",
    "# Filter the original DataFrame to only include rows where the count of non-NaN results is greater than 0 (there was a 3nd iteration)\n",
    "df_filtered = current_df.merge(grouped_df, on=['model_name', 'template']).drop_duplicates(subset=['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'result_3', 'target_filename'])\n",
    "df_filtered = df_filtered[df_filtered['count_non_nan_result_3'] > 0]\n",
    "df_filtered\n",
    "results_total_third_iteration = df_filtered[['dataset', 'source_lang', 'target_lang', 'model_name', 'template', 'result_1', 'result_2', 'result_3', 'target_filename']].fillna({\"result_2\": \"success\", \"result_3\": \"success\"})\n",
    "results_total_third_iteration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
